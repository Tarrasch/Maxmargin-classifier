\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}

\title{Duality Forumlation of Max-Margin Classifier\footnote{This is the first time I use latex}} 
\author{Arash Rouhani}

\begin{document}

\maketitle

\begin{abstract}
In this fake-paper I write a short mathematical explenation
of how to formulate the Max-Margin classifier in it's dual form.
I go through it step by step. 

\end{abstract}

\section{Primal formulation}
To be written ...
\section{Lagrangian function}
There will be as always 3 kinds of terms, coming from either the \textit{the objective function},\textit{a constraint} or \textit{a variable constraint}.
% \begin{equation}
% L(w, b, \xi, \mu, \nu) = \frac{1}{2} ||w||^2_2 + \sum\limits_{i=1}^n {C\xi_i - \mu_iy_i(w^Tx_i - b + \xi_i - 1) - \nu_i\xi_i}
% \end{equation}
% Can simply be rewritten to
\begin{equation}
L(w, b, \xi, \mu, \nu) = \frac{1}{2} ||w||^2_2 + \sum\limits_{i=1}^n {C\xi_i + \mu_i(y_ib + 1 - y_iw^Tx_i - \xi_i) - \nu_i\xi_i}
\end{equation}
We now derivativs for each variable-type and get an equation. There are 3 'types' of variables here, so we will get 3 equations.

\subsection{Derivative with respect to w}
  \begin{equation}
    \frac{dL}{dw} = 0 = w - \sum\limits_{i=1}^n {\mu_i y_i x_i}
  \end{equation}
% WRONG - %  Here $x_i$ means the sum of the values in the \textbf{vector} $x_i$.
\subsection{Derivative with respect to b}
  \begin{equation}
    \frac{dL}{db} = 0 = \sum\limits_{i=1}^n {\mu_i y_i}
  \end{equation}
\subsection{Derivative with respect to $\xi$}
  \begin{equation}
    \frac{dL}{db} = 0 = C - \mu_i - \nu_i
  \end{equation}

\section{Reducing the lagrangian by substitution}
First we substitute (4) which is clearly eliminating the $\xi$ terms.
\begin{equation}
  L(w, b, \mu) = \frac{1}{2} ||w||^2_2 + \sum\limits_{i=1}^n {\mu_i(y_ib + 1 - y_iw^Tx_i)}
\end{equation}
Let's rewrite the function using $ ||w||^2_2 = w^Tw $ and other simple rewritings.
\begin{equation}
  L(w, b, \mu) = w^T(\frac{1}{2}w - \sum\limits_{i=1}^n {\mu_iy_ix_i}) + b\sum\limits_{i=1}^n {\mu_iy_i} + \sum\limits_{i=1}^n {\mu_i}
\end{equation}
First we use (2) and (3) in order to reduce once more.
\begin{equation}
  L(w, \mu) = \sum\limits_{i=1}^n {\mu_i} - \frac{1}{2} w^T \sum\limits_{i=1}^n{\mu_iy_ix_i} 
\end{equation}
\end{document}
