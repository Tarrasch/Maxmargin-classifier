\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}

\title{Duality Forumlation of Max-Margin Classifier\footnote{This is the first time I use latex}} 
\author{Arash Rouhani}

\begin{document}

\maketitle

\begin{abstract}
This paper presents a short mathematical explenation of how to formulate
the Max-Margin Classifier problem in it's dual form.
I go through the derivation step by step by formulating the lagrangian
function and then performing sensible steps finally reach the desired dual formulation. 

\end{abstract}

\section{Primal formulation}
To be written ...
\section{Lagrangian function}
There will be as always 3 kinds of terms, coming from either the \textit{the objective function},\textit{a constraint} or \textit{a variable constraint}.
% \begin{equation}
% L(w, b, \xi, \mu, \nu) = \frac{1}{2} ||w||^2_2 + \sum\limits_{i=1}^n {C\xi_i - \mu_iy_i(w^Tx_i - b + \xi_i - 1) - \nu_i\xi_i}
% \end{equation}
% Can simply be rewritten to
\begin{equation}
L(w, b, \xi, \mu, \nu) = \frac{1}{2} ||w||^2_2 + \sum\limits_{i=1}^n {C\xi_i + \mu_i(y_ib + 1 - y_iw^Tx_i - \xi_i) - \nu_i\xi_i}
\end{equation}
We now derivativs for each variable-type and get an equation. There are 3 'types' of variables here, so we will get 3 equations.

\subsection{Derivative with respect to w}
  \begin{equation}
    \frac{dL}{dw} = \textbf{0} = w - \sum\limits_{i=1}^n {\mu_i y_i x_i}
  \end{equation}
% WRONG - %  Here $x_i$ means the sum of the values in the \textbf{vector} $x_i$.
\subsection{Derivative with respect to b}
  \begin{equation}
    \frac{dL}{db} = 0 = \sum\limits_{i=1}^n {\mu_i y_i}
  \end{equation}
\subsection{Derivative with respect to $\xi$}
  \begin{equation}
    \frac{dL}{db} = 0 = C - \mu_i - \nu_i
  \end{equation}

\section{Reducing the lagrangian by substitution}
First we substitute (4) which is clearly eliminating the $\xi$ terms.
\begin{equation}
  L(w, b, \mu) = \frac{1}{2} ||w||^2_2 + \sum\limits_{i=1}^n {\mu_i(y_ib + 1 - y_iw^Tx_i)}
\end{equation}
Let's rewrite the function using $ ||w||^2_2 = w^Tw $ and other simple rewritings.
\begin{equation}
  L(w, b, \mu) = w^T(\frac{1}{2}w - \sum\limits_{i=1}^n {\mu_iy_ix_i}) + b\sum\limits_{i=1}^n {\mu_iy_i} + \sum\limits_{i=1}^n {\mu_i}
\end{equation}
Now we use (2) and (3) in order to reduce once more.
\begin{equation}
  L(w, \mu) = \sum\limits_{i=1}^n {\mu_i} - \frac{1}{2} w^T \sum\limits_{i=1}^n{\mu_iy_ix_i} 
\end{equation}
Now we use (2) again to rewrite $w^T$, finally eliminating all free varaibles we had in the primal.
\begin{equation}
  L(\mu) = \sum\limits_{i=1}^n {\mu_i} - \frac{1}{2} \sum\limits_{j=1}^n{\mu_jy_jx_j^T} \sum\limits_{i=1}^n{\mu_iy_ix_i} 
\end{equation}
Now we finally rewrite the lagrangian to it's well-recognized form.
\begin{equation}
  L(\mu) = \sum\limits_{i=1}^n {\mu_i} - \frac{1}{2} \sum\limits_{i=1}^n \sum\limits_{j=1}^n{\mu_i\mu_jy_iy_jx_i^Tx_j}
\end{equation}
\section{Finding the constraints}
So far we've only retrieved the objective function out of the Lagrangian, but what about the constraints?
Firstly we must notice that we've always known that $ \mu,\nu > 0 $
as dual variables always have that property (otherwise it wouldn't be
penalty to violate the constraints).
The rest of the information we are going to work with is the equalities
we got after the derivations in the previous chapter.


The first constraint we take is simply equation (3). The second constraint I claim is
$$ 0 \le \mu_i \le C $$
$$ 1 \le     i \le n $$ 

$\mu_i \ge 0$ Holds by definition. $C \ge \mu_i$ since we can freely choose $\nu \ge 0$.
By regulating \nu in $\mu_i = C - \nu_i$ it becomes clear that we get the constraint claimed above.


\end{document}
